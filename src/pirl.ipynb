{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da4f6153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n",
      "\n",
      "\n",
      "Default GPU Device: /device:GPU:0\n",
      "Torch version: 2.1.1+cu121\n",
      "Is CUDA enabled? True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import torch \n",
    "\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")\n",
    "\n",
    "print('\\n\\nDefault GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "\n",
    "print(\"Torch version:\",torch.__version__)\n",
    "\n",
    "print(\"Is CUDA enabled?\",torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e80e5606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=10, micro=0, releaselevel='final', serial=0)\n",
      "Using existing file: stl10_binary.tar.gz\n",
      "(5000, 96, 96, 3)\n",
      "(5000,)\n",
      "Saving images to disk\n",
      "(8000, 96, 96, 3)\n",
      "(8000,)\n",
      "Saving images to disk\n",
      "(100000, 96, 96, 3)\n",
      "Saving images to disk\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Script obtained from: https://github.com/mttk/STL10/blob/master/stl10_input.py\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import os, sys, tarfile, errno\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "if sys.version_info >= (3, 0, 0):\n",
    "    import urllib.request as urllib  # ugly but works\n",
    "else:\n",
    "    import urllib\n",
    "\n",
    "print(sys.version_info)\n",
    "\n",
    "# image shape\n",
    "HEIGHT = 96\n",
    "WIDTH = 96\n",
    "DEPTH = 3\n",
    "\n",
    "# size of a single image in bytes\n",
    "SIZE = HEIGHT * WIDTH * DEPTH\n",
    "\n",
    "# path to the directory with the data\n",
    "DATA_DIR = './raw_stl10/'\n",
    "STL10_TRAIN_IMG_DIR = './stl10_data/train/'\n",
    "STL10_TEST_IMG_DIR = './stl10_data/test/'\n",
    "STL10_UNLABELLED_IMG_DIR = './stl10_data/unlabelled/'\n",
    "\n",
    "# url of the binary data\n",
    "DATA_URL = 'stl10_binary.tar.gz'\n",
    "\n",
    "# path to the binary files with image data\n",
    "TRAIN_DATA_PATH = os.path.join(DATA_DIR ,'stl10_binary/train_X.bin')\n",
    "TEST_DATA_PATH = os.path.join(DATA_DIR , 'stl10_binary/test_X.bin')\n",
    "UNLABELLED_DATA_PATH = os.path.join(DATA_DIR, 'stl10_binary/unlabeled_X.bin')\n",
    "\n",
    "# path to the binary files with labels\n",
    "TRAIN_LABEL_PATH = os.path.join(DATA_DIR, 'stl10_binary/train_y.bin')\n",
    "TEST_LABEL_PATH = os.path.join(DATA_DIR, 'stl10_binary/test_y.bin')\n",
    "\n",
    "\n",
    "def read_labels(path_to_labels):\n",
    "    \"\"\"\n",
    "    :param path_to_labels: path to the binary file containing labels from the STL-10 dataset\n",
    "    :return: an array containing the labels\n",
    "    \"\"\"\n",
    "    with open(path_to_labels, 'rb') as f:\n",
    "        labels = np.fromfile(f, dtype=np.uint8)\n",
    "        return labels\n",
    "\n",
    "\n",
    "def read_all_images(path_to_data):\n",
    "    \"\"\"\n",
    "    :param path_to_data: the file containing the binary images from the STL-10 dataset\n",
    "    :return: an array containing all the images\n",
    "    \"\"\"\n",
    "\n",
    "    with open(path_to_data, 'rb') as f:\n",
    "        # read whole file in uint8 chunks\n",
    "        everything = np.fromfile(f, dtype=np.uint8)\n",
    "\n",
    "        # We force the data into 3x96x96 chunks, since the\n",
    "        # images are stored in \"column-major order\", meaning\n",
    "        # that \"the first 96*96 values are the red channel,\n",
    "        # the next 96*96 are green, and the last are blue.\"\n",
    "        # The -1 is since the size of the pictures depends\n",
    "        # on the input file, and this way numpy determines\n",
    "        # the size on its own.\n",
    "\n",
    "        images = np.reshape(everything, (-1, 3, 96, 96))\n",
    "\n",
    "        # Now transpose the images into a standard image format\n",
    "        # readable by, for example, matplotlib.imshow\n",
    "        # You might want to comment this line or reverse the shuffle\n",
    "        # if you will use a learning algorithm like CNN, since they like\n",
    "        # their channels separated.\n",
    "        images = np.transpose(images, (0, 3, 2, 1))\n",
    "        return images\n",
    "\n",
    "\n",
    "def save_image(image, name):\n",
    "    image = Image.fromarray(image)\n",
    "    image.save(name + '.jpeg')\n",
    "\n",
    "\n",
    "def download_and_extract():\n",
    "    \"\"\"\n",
    "    Download and extract the STL-10 dataset if not already present\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    dest_directory = DATA_DIR\n",
    "    if not os.path.exists(dest_directory):\n",
    "        os.makedirs(dest_directory)\n",
    "        \n",
    "    filename = DATA_URL.split('/')[-1]\n",
    "    filepath = os.path.join(dest_directory, filename)\n",
    "    \n",
    "    # Check if the file already exists\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"The file {filename} is not found in the specified directory. Please make sure the file is present.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Using existing file: {filename}\")\n",
    "    tarfile.open(filepath, 'r:gz').extractall(dest_directory)\n",
    "\n",
    "\n",
    "def save_images(images_dir, images, labels):\n",
    "    print(\"Saving images to disk\")\n",
    "    i = 0\n",
    "    for image in images:\n",
    "        if labels is not None:\n",
    "            directory = os.path.join(images_dir, str(labels[i]))\n",
    "        else:\n",
    "            directory = images_dir\n",
    "\n",
    "        try:\n",
    "            os.makedirs(directory, exist_ok=True)\n",
    "        except OSError as exc:\n",
    "            if exc.errno == errno.EEXIST:\n",
    "                pass\n",
    "\n",
    "        filename = os.path.join(directory, str(i))\n",
    "        # print(filename)\n",
    "        save_image(image, filename)\n",
    "        i = i + 1\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # download data if needed\n",
    "    download_and_extract()\n",
    "\n",
    "    # Read train-images and labels and save to disk\n",
    "    images = read_all_images(TRAIN_DATA_PATH)\n",
    "    print(images.shape)\n",
    "\n",
    "    labels = read_labels(TRAIN_LABEL_PATH)\n",
    "    print(labels.shape)\n",
    "\n",
    "    save_images(STL10_TRAIN_IMG_DIR, images, labels)\n",
    "\n",
    "    # Read test-images and labels and save to disk\n",
    "    images = read_all_images(TEST_DATA_PATH)\n",
    "    print(images.shape)\n",
    "\n",
    "    labels = read_labels(TEST_LABEL_PATH)\n",
    "    print(labels.shape)\n",
    "\n",
    "    save_images(STL10_TEST_IMG_DIR, images, labels)\n",
    "\n",
    "    # Read unlabelled images and save to disk\n",
    "    images = read_all_images(UNLABELLED_DATA_PATH)\n",
    "    labels = None\n",
    "    print (images.shape)\n",
    "\n",
    "    save_images(STL10_UNLABELLED_IMG_DIR, images, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "639e1da9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module '__main__' has no attribute '__spec__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m~\\Desktop\\BAU\\2. DÃ¶nem\\Deep Learning\\Project Proposal\\project\\pirl\\pirl_stl_train_test.py:103\u001b[0m\n\u001b[0;32m     99\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(val_set, batch_size\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mbatch_size, sampler\u001b[38;5;241m=\u001b[39mval_sampler,\n\u001b[0;32m    100\u001b[0m                                          num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# Print sample batches that would be returned by the train_data_loader\u001b[39;00m\n\u001b[1;32m--> 103\u001b[0m dataiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m X, y \u001b[38;5;241m=\u001b[39m dataiter\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__next__\u001b[39m()\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28mprint\u001b[39m (X[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:438\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:386\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1039\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1032\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1039\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\multiprocessing\\context.py:327\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\multiprocessing\\popen_spawn_win32.py:45\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[1;32m---> 45\u001b[0m     prep_data \u001b[38;5;241m=\u001b[39m \u001b[43mspawn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_preparation_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;66;03m# read end of pipe will be duplicated by the child process\u001b[39;00m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;66;03m# -- see spawn_main() in spawn.py.\u001b[39;00m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# bpo-33929: Previously, the read end of pipe was \"stolen\" by the child\u001b[39;00m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;66;03m# process, but it leaked a handle if the child process had been\u001b[39;00m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;66;03m# terminated before it could steal the handle from the parent process.\u001b[39;00m\n\u001b[0;32m     53\u001b[0m     rhandle, whandle \u001b[38;5;241m=\u001b[39m _winapi\u001b[38;5;241m.\u001b[39mCreatePipe(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\multiprocessing\\spawn.py:183\u001b[0m, in \u001b[0;36mget_preparation_data\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;66;03m# Figure out whether to initialise main in the subprocess as a module\u001b[39;00m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;66;03m# or through direct execution (or to leave it alone entirely)\u001b[39;00m\n\u001b[0;32m    182\u001b[0m main_module \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mmodules[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m--> 183\u001b[0m main_mod_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[43mmain_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__spec__\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m main_mod_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    185\u001b[0m     d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minit_main_from_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m main_mod_name\n",
      "\u001b[1;31mAttributeError\u001b[0m: module '__main__' has no attribute '__spec__'"
     ]
    }
   ],
   "source": [
    "file_name = \"pirl_stl_train_test.py\"\n",
    "\n",
    "%run \"$file_name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239b9ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02261351",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
